{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McByte: Multi-Object Tracking with Mask Propagation\n",
    "\n",
    "This notebook provides an easy-to-use interface for running McByte tracking with:\n",
    "- **YOLOv8** detector (your custom weights)\n",
    "- **Modular tracker selection** (McByte, ByteTrack, SORT, DeepSORT, BoT-SORT, OC-SORT)\n",
    "- **SAM + Cutie** mask propagation\n",
    "- **MP4 video** input/output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core dependencies\n",
    "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q ultralytics  # YOLOv8\n",
    "!pip install -q segment-anything  # SAM\n",
    "!pip install -q hydra-core omegaconf einops\n",
    "\n",
    "# Tracking dependencies\n",
    "!pip install -q lap filterpy cython_bbox\n",
    "\n",
    "# Optional: Additional trackers\n",
    "# !pip install -q sort-tracker  # For SORT\n",
    "# !pip install -q deep-sort-realtime  # For DeepSORT\n",
    "# !pip install -q ocsort  # For OC-SORT\n",
    "\n",
    "# Clone McByte repository\n",
    "!git clone https://github.com/HiteshG/McByte.git\n",
    "%cd McByte\n",
    "\n",
    "# Build C++ extensions\n",
    "!python setup.py develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(\"sam_models\", exist_ok=True)\n",
    "os.makedirs(\"mask_propagation/Cutie/weights\", exist_ok=True)\n",
    "\n",
    "# === SAM Model Selection ===\n",
    "sam_type = \"vit_b\"  # @param [\"vit_b\", \"vit_l\", \"vit_h\"]\n",
    "\n",
    "SAM_URLS = {\n",
    "    \"vit_b\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\",\n",
    "    \"vit_l\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\",\n",
    "    \"vit_h\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\",\n",
    "}\n",
    "\n",
    "sam_filename = f\"sam_{sam_type}.pth\"\n",
    "sam_path = f\"sam_models/{sam_filename}\"\n",
    "\n",
    "if not os.path.exists(sam_path):\n",
    "    print(f\"Downloading SAM {sam_type}...\")\n",
    "    !wget -q {SAM_URLS[sam_type]} -O {sam_path}\n",
    "    print(f\"SAM downloaded to: {sam_path}\")\n",
    "else:\n",
    "    print(f\"SAM already exists: {sam_path}\")\n",
    "\n",
    "# === Optional: SAM2 ===\n",
    "use_sam2 = False  # @param {type:\"boolean\"}\n",
    "\n",
    "if use_sam2:\n",
    "    !pip install -q sam2\n",
    "    from huggingface_hub import hf_hub_download\n",
    "    sam2_path = hf_hub_download(\n",
    "        repo_id=\"facebook/sam2-hiera-large\",\n",
    "        filename=\"sam2_hiera_large.pt\",\n",
    "        local_dir=\"sam_models\"\n",
    "    )\n",
    "    sam_type = \"sam2\"\n",
    "    sam_path = sam2_path\n",
    "    print(f\"SAM2 downloaded to: {sam_path}\")\n",
    "\n",
    "# === Cutie ===\n",
    "cutie_path = \"mask_propagation/Cutie/weights/cutie-base-mega.pth\"\n",
    "\n",
    "if not os.path.exists(cutie_path):\n",
    "    print(\"Downloading Cutie weights...\")\n",
    "    !wget -q https://github.com/hkchengrex/Cutie/releases/download/v1.0/cutie-base-mega.pth \\\n",
    "        -O {cutie_path}\n",
    "    print(f\"Cutie downloaded to: {cutie_path}\")\n",
    "else:\n",
    "    print(f\"Cutie already exists: {cutie_path}\")\n",
    "\n",
    "print(\"\\n=== Model weights ready ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Configure your tracking settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# YOUR CONFIGURATION - MODIFY THESE VALUES\n",
    "# =============================================================================\n",
    "\n",
    "# === YOLOv8 Model ===\n",
    "# Upload your .pt file to Colab and set the path here\n",
    "YOLOV8_WEIGHTS = \"/content/your_model.pt\"  # @param {type:\"string\"}\n",
    "\n",
    "# Your model's class names (in order)\n",
    "CLASS_NAMES = [\"person\", \"ball\"]  # @param\n",
    "\n",
    "# === Tracker Selection ===\n",
    "# Options: \"mcbyte\", \"bytetrack\", \"sort\", \"deepsort\", \"botsort\", \"ocsort\"\n",
    "TRACKER_TYPE = \"mcbyte\"  # @param [\"mcbyte\", \"bytetrack\", \"sort\", \"deepsort\", \"botsort\", \"ocsort\"]\n",
    "\n",
    "# === Tracking Parameters ===\n",
    "TRACK_THRESH = 0.6  # @param {type:\"slider\", min:0.1, max:0.9, step:0.05}\n",
    "TRACK_BUFFER = 30  # @param {type:\"slider\", min:10, max:100, step:5}\n",
    "\n",
    "# === SAM Configuration ===\n",
    "# Uses values from previous cell\n",
    "SAM_CHECKPOINT = sam_path\n",
    "SAM_TYPE = sam_type\n",
    "\n",
    "# === Cutie Configuration ===\n",
    "CUTIE_WEIGHTS = cutie_path\n",
    "\n",
    "# === Other Options ===\n",
    "ENABLE_MASKS = True  # @param {type:\"boolean\"}\n",
    "VIS_TYPE = \"basic\"  # @param [\"basic\", \"no_vis\"]\n",
    "CONF_THRESH = 0.01  # @param {type:\"number\"}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  YOLOv8 weights: {YOLOV8_WEIGHTS}\")\n",
    "print(f\"  Class names: {CLASS_NAMES}\")\n",
    "print(f\"  Tracker: {TRACKER_TYPE}\")\n",
    "print(f\"  Track threshold: {TRACK_THRESH}\")\n",
    "print(f\"  Track buffer: {TRACK_BUFFER}\")\n",
    "print(f\"  SAM type: {SAM_TYPE}\")\n",
    "print(f\"  Masks enabled: {ENABLE_MASKS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation Checks\n",
    "\n",
    "Verify that all components are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def validate_setup():\n",
    "    \"\"\"Validate all components are working.\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"[1/4] Device: {device} ({'GPU: ' + torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'})\")\n",
    "\n",
    "    # === YOLOv8 Check ===\n",
    "    print(\"[2/4] Checking YOLOv8...\")\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "        model = YOLO(YOLOV8_WEIGHTS)\n",
    "        test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "        results = model(test_img, verbose=False)\n",
    "        print(f\"  [OK] YOLOv8 loaded: {len(model.names)} classes\")\n",
    "        print(f\"  [OK] Custom classes: {CLASS_NAMES}\")\n",
    "        del model\n",
    "    except Exception as e:\n",
    "        print(f\"  [FAIL] YOLOv8: {e}\")\n",
    "        return False\n",
    "\n",
    "    # === SAM Check ===\n",
    "    print(\"[3/4] Checking SAM...\")\n",
    "    try:\n",
    "        if SAM_TYPE == \"sam2\":\n",
    "            from sam2.build_sam import build_sam2\n",
    "            from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "            sam = build_sam2(SAM_CHECKPOINT)\n",
    "            sam.to(device)\n",
    "            predictor = SAM2ImagePredictor(sam)\n",
    "        else:\n",
    "            from segment_anything import sam_model_registry, SamPredictor\n",
    "            sam = sam_model_registry[SAM_TYPE](checkpoint=SAM_CHECKPOINT)\n",
    "            sam.to(device)\n",
    "            predictor = SamPredictor(sam)\n",
    "\n",
    "        test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "        predictor.set_image(test_img)\n",
    "        masks, scores, _ = predictor.predict(\n",
    "            box=np.array([100, 100, 300, 300]),\n",
    "            multimask_output=False\n",
    "        )\n",
    "        print(f\"  [OK] SAM working: mask shape {masks.shape}, score {scores[0]:.3f}\")\n",
    "        del sam, predictor\n",
    "    except Exception as e:\n",
    "        print(f\"  [FAIL] SAM: {e}\")\n",
    "        return False\n",
    "\n",
    "    # === Cutie Check ===\n",
    "    print(\"[4/4] Checking Cutie...\")\n",
    "    try:\n",
    "        sys.path.insert(0, \"mask_propagation/Cutie\")\n",
    "        from cutie.model.cutie import CUTIE\n",
    "        from hydra import initialize, compose\n",
    "        from hydra.core.global_hydra import GlobalHydra\n",
    "        from omegaconf import open_dict\n",
    "        from cutie.inference.utils.args_utils import get_dataset_cfg\n",
    "\n",
    "        GlobalHydra.instance().clear()\n",
    "        initialize(version_base='1.3.2', config_path=\"mask_propagation/Cutie/cutie/config\")\n",
    "        cfg = compose(config_name=\"eval_config\")\n",
    "\n",
    "        with open_dict(cfg):\n",
    "            cfg['weights'] = CUTIE_WEIGHTS\n",
    "\n",
    "        _ = get_dataset_cfg(cfg)\n",
    "\n",
    "        cutie = CUTIE(cfg).to(device).eval()\n",
    "        weights = torch.load(CUTIE_WEIGHTS, map_location=device)\n",
    "        cutie.load_weights(weights)\n",
    "        print(\"  [OK] Cutie loaded successfully\")\n",
    "        del cutie\n",
    "    except Exception as e:\n",
    "        print(f\"  [FAIL] Cutie: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Cleanup\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"[OK] All validation checks passed!\")\n",
    "    print(\"=\"*50)\n",
    "    return True\n",
    "\n",
    "# Run validation\n",
    "validation_passed = validate_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Inference\n",
    "\n",
    "Upload your video and run tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from tools.colab_inference import run_inference\n",
    "\n",
    "# Upload video\n",
    "print(\"Please upload your video file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    video_path = list(uploaded.keys())[0]\n",
    "    print(f\"\\nUploaded: {video_path}\")\n",
    "else:\n",
    "    raise ValueError(\"No video uploaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tracking with masks\n",
    "print(\"Starting inference...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "output_path = run_inference(\n",
    "    video_path=video_path,\n",
    "    yolov8_weights=YOLOV8_WEIGHTS,\n",
    "    tracker_type=TRACKER_TYPE,\n",
    "    track_thresh=TRACK_THRESH,\n",
    "    track_buffer=TRACK_BUFFER,\n",
    "    sam_checkpoint=SAM_CHECKPOINT,\n",
    "    sam_type=SAM_TYPE,\n",
    "    cutie_weights=CUTIE_WEIGHTS,\n",
    "    enable_masks=ENABLE_MASKS,\n",
    "    class_names=CLASS_NAMES,\n",
    "    vis_type=VIS_TYPE,\n",
    "    conf_thresh=CONF_THRESH,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nOutput saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display and Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "from base64 import b64encode\n",
    "import os\n",
    "\n",
    "# Display video in notebook\n",
    "def show_video(video_path, width=800):\n",
    "    \"\"\"Display video in notebook.\"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video not found: {video_path}\")\n",
    "        return\n",
    "\n",
    "    # Read video file\n",
    "    with open(video_path, 'rb') as f:\n",
    "        mp4 = f.read()\n",
    "\n",
    "    # Encode to base64\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "\n",
    "    # Display\n",
    "    display(HTML(f'''\n",
    "        <video width={width} controls>\n",
    "            <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "            Your browser does not support the video tag.\n",
    "        </video>\n",
    "    '''))\n",
    "\n",
    "print(\"Displaying output video...\")\n",
    "show_video(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download output video\n",
    "from google.colab import files\n",
    "\n",
    "print(f\"Downloading: {output_path}\")\n",
    "files.download(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (Optional) Process Multiple Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing example\n",
    "import os\n",
    "from tools.colab_inference import run_inference\n",
    "\n",
    "def process_videos_batch(video_dir, output_dir=\"outputs\"):\n",
    "    \"\"\"\n",
    "    Process all videos in a directory.\n",
    "\n",
    "    Args:\n",
    "        video_dir: Directory containing input videos\n",
    "        output_dir: Directory for output videos\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
    "    videos = [\n",
    "        f for f in os.listdir(video_dir)\n",
    "        if any(f.lower().endswith(ext) for ext in video_extensions)\n",
    "    ]\n",
    "\n",
    "    print(f\"Found {len(videos)} videos to process\")\n",
    "\n",
    "    results = []\n",
    "    for i, video_name in enumerate(videos, 1):\n",
    "        print(f\"\\n[{i}/{len(videos)}] Processing: {video_name}\")\n",
    "\n",
    "        input_path = os.path.join(video_dir, video_name)\n",
    "        output_name = f\"tracked_{video_name}\"\n",
    "        output_path = os.path.join(output_dir, output_name)\n",
    "\n",
    "        try:\n",
    "            result = run_inference(\n",
    "                video_path=input_path,\n",
    "                yolov8_weights=YOLOV8_WEIGHTS,\n",
    "                output_path=output_path,\n",
    "                tracker_type=TRACKER_TYPE,\n",
    "                track_thresh=TRACK_THRESH,\n",
    "                track_buffer=TRACK_BUFFER,\n",
    "                sam_checkpoint=SAM_CHECKPOINT,\n",
    "                sam_type=SAM_TYPE,\n",
    "                cutie_weights=CUTIE_WEIGHTS,\n",
    "                enable_masks=ENABLE_MASKS,\n",
    "                class_names=CLASS_NAMES,\n",
    "                verbose=False,\n",
    "            )\n",
    "            results.append((video_name, result, \"success\"))\n",
    "            print(f\"  [OK] Output: {result}\")\n",
    "        except Exception as e:\n",
    "            results.append((video_name, None, str(e)))\n",
    "            print(f\"  [FAIL] {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Batch processing complete!\")\n",
    "    print(f\"Success: {sum(1 for r in results if r[2] == 'success')}/{len(results)}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "# results = process_videos_batch(\"/content/videos\", \"/content/outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. (Optional) Custom Tracker Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using different trackers with custom parameters\n",
    "from tools.tracker_interface import create_tracker, list_available_trackers\n",
    "\n",
    "# List available trackers\n",
    "print(\"Available trackers:\")\n",
    "for tracker_name in list_available_trackers():\n",
    "    print(f\"  - {tracker_name}\")\n",
    "\n",
    "# Example configurations for different trackers:\n",
    "\n",
    "# McByte (default - with mask-enhanced matching)\n",
    "mcbyte_tracker = create_tracker(\n",
    "    tracker_type=\"mcbyte\",\n",
    "    track_thresh=0.6,\n",
    "    track_buffer=30,\n",
    "    cmc_method=\"orb\",  # Camera motion compensation\n",
    ")\n",
    "\n",
    "# ByteTrack (standard, without mask enhancement)\n",
    "bytetrack_tracker = create_tracker(\n",
    "    tracker_type=\"bytetrack\",\n",
    "    track_thresh=0.5,\n",
    "    track_buffer=30,\n",
    ")\n",
    "\n",
    "# SORT (simple Kalman + Hungarian)\n",
    "sort_tracker = create_tracker(\n",
    "    tracker_type=\"sort\",\n",
    "    track_buffer=30,\n",
    "    min_hits=3,\n",
    "    iou_threshold=0.3,\n",
    ")\n",
    "\n",
    "# DeepSORT (with ReID features)\n",
    "# Note: Requires pip install deep-sort-realtime\n",
    "# deepsort_tracker = create_tracker(\n",
    "#     tracker_type=\"deepsort\",\n",
    "#     track_buffer=30,\n",
    "#     n_init=3,\n",
    "#     embedder=\"mobilenet\",\n",
    "# )\n",
    "\n",
    "print(\"\\nTrackers configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **CUDA out of memory**: Reduce `max_internal_size` in Cutie config or use a smaller SAM model (vit_b)\n",
    "\n",
    "2. **YOLOv8 model not found**: Make sure you've uploaded your .pt file and set the correct path\n",
    "\n",
    "3. **SAM download failed**: Manually download from the URLs and upload to Colab\n",
    "\n",
    "4. **Tracker package not found**: Install the required package:\n",
    "   - SORT: `pip install sort-tracker`\n",
    "   - DeepSORT: `pip install deep-sort-realtime`\n",
    "   - OC-SORT: `pip install ocsort`\n",
    "\n",
    "### Memory Optimization:\n",
    "\n",
    "Edit `mask_propagation/Cutie/cutie/config/eval_config.yaml`:\n",
    "```yaml\n",
    "max_internal_size: 540  # Reduce from -1 (original resolution)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**McByte** - CVPRW 2025 | [GitHub](https://github.com/HiteshG/McByte)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
