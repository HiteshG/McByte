{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McByte: Multi-Object Tracking with Mask Propagation\n",
    "\n",
    "This notebook provides an easy-to-use interface for running McByte tracking with:\n",
    "- **YOLOv8** detector (your custom weights)\n",
    "- **Modular tracker selection** (McByte, ByteTrack, SORT, DeepSORT, BoT-SORT, OC-SORT)\n",
    "- **SAM + Cutie** mask propagation\n",
    "- **MP4 video** input/output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core dependencies\n",
    "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q ultralytics  # YOLOv8\n",
    "!pip install -q segment-anything  # SAM\n",
    "!pip install -q hydra-core omegaconf einops\n",
    "!pip install -q loguru\n",
    "\n",
    "# Tracking dependencies\n",
    "!pip install -q lap filterpy cython_bbox\n",
    "\n",
    "# Optional: Additional trackers\n",
    "# !pip install -q sort-tracker  # For SORT\n",
    "# !pip install -q deep-sort-realtime  # For DeepSORT\n",
    "# !pip install -q ocsort  # For OC-SORT\n",
    "\n",
    "# Clone McByte repository\n",
    "!git clone https://github.com/HiteshG/McByte.git\n",
    "%cd McByte\n",
    "\n",
    "# Build C++ extensions\n",
    "!python setup.py develop"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 1.5 Hugging Face Authentication (Required for SAM2/SAM3)\n\nIf you plan to use SAM2 or SAM3, you need to authenticate with Hugging Face to download the model weights.\n\n**Steps:**\n1. Create a Hugging Face account at https://huggingface.co\n2. Generate an access token at https://huggingface.co/settings/tokens\n3. Accept the license for the SAM2 model at https://huggingface.co/facebook/sam2-hiera-large\n4. Paste your token below when prompted",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# === Hugging Face Token Authentication ===\n# Run this cell and paste your token when prompted (input will be hidden)\n\nfrom getpass import getpass\nimport os\n\n# Check if already logged in\ntry:\n    from huggingface_hub import HfFolder\n    existing_token = HfFolder.get_token()\n    if existing_token:\n        print(\"[OK] Already logged in to Hugging Face\")\n        HF_TOKEN = existing_token\n    else:\n        raise ValueError(\"No token found\")\nexcept:\n    print(\"Hugging Face authentication required for SAM2/SAM3 downloads.\")\n    print(\"Get your token from: https://huggingface.co/settings/tokens\\n\")\n    \n    HF_TOKEN = getpass(\"Paste your Hugging Face token here: \")\n    \n    if HF_TOKEN:\n        # Login to Hugging Face\n        from huggingface_hub import login\n        login(token=HF_TOKEN, add_to_git_credential=False)\n        print(\"\\n[OK] Successfully logged in to Hugging Face!\")\n    else:\n        print(\"\\n[WARNING] No token provided. SAM2/SAM3 download may fail.\")\n        print(\"You can still use SAM (vit_b/vit_l/vit_h) without authentication.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# Create directories\nos.makedirs(\"sam_models\", exist_ok=True)\nos.makedirs(\"mask_propagation/Cutie/weights\", exist_ok=True)\n\n# === SAM Model Selection ===\nsam_type = \"vit_b\"  # @param [\"vit_b\", \"vit_l\", \"vit_h\"]\n\nSAM_URLS = {\n    \"vit_b\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\",\n    \"vit_l\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\",\n    \"vit_h\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\",\n}\n\nsam_filename = f\"sam_{sam_type}.pth\"\nsam_path = f\"sam_models/{sam_filename}\"\n\nif not os.path.exists(sam_path):\n    print(f\"Downloading SAM {sam_type}...\")\n    !wget -q {SAM_URLS[sam_type]} -O {sam_path}\n    print(f\"SAM downloaded to: {sam_path}\")\nelse:\n    print(f\"SAM already exists: {sam_path}\")\n\n# === Optional: SAM2 ===\n# Make sure you ran the Hugging Face authentication cell above first!\nuse_sam2 = False  # @param {type:\"boolean\"}\n\nif use_sam2:\n    print(\"Installing SAM2...\")\n    !pip install -q sam2\n\n    from huggingface_hub import hf_hub_download, HfFolder\n\n    # Get token (from login or stored)\n    token = HfFolder.get_token()\n    if not token:\n        print(\"[WARNING] No Hugging Face token found!\")\n        print(\"Please run the authentication cell above first.\")\n        raise ValueError(\"Hugging Face authentication required for SAM2\")\n\n    print(\"Downloading SAM2 weights from Hugging Face...\")\n    sam2_path = hf_hub_download(\n        repo_id=\"facebook/sam2-hiera-large\",\n        filename=\"sam2_hiera_large.pt\",\n        local_dir=\"sam_models\",\n        token=token\n    )\n    sam_type = \"sam2\"\n    sam_path = sam2_path\n    print(f\"SAM2 downloaded to: {sam_path}\")\n\n# === Cutie ===\ncutie_path = \"mask_propagation/Cutie/weights/cutie-base-mega.pth\"\n\nif not os.path.exists(cutie_path):\n    print(\"Downloading Cutie weights...\")\n    !wget -q https://github.com/hkchengrex/Cutie/releases/download/v1.0/cutie-base-mega.pth \\\n        -O {cutie_path}\n    print(f\"Cutie downloaded to: {cutie_path}\")\nelse:\n    print(f\"Cutie already exists: {cutie_path}\")\n\nprint(\"\\n=== Model weights ready ===\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Configure your tracking settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# YOUR CONFIGURATION - MODIFY THESE VALUES\n",
    "# =============================================================================\n",
    "\n",
    "# === YOLOv8 Model ===\n",
    "# Upload your .pt file to Colab and set the path here\n",
    "YOLOV8_WEIGHTS = \"/content/your_model.pt\"  # @param {type:\"string\"}\n",
    "\n",
    "# Your model's class names (in order of class IDs)\n",
    "CLASS_NAMES = [\n",
    "    \"Center Ice\",   # 0\n",
    "    \"Faceoff\",      # 1\n",
    "    \"Goalpost\",     # 2\n",
    "    \"Goaltender\",   # 3\n",
    "    \"Player\",       # 4\n",
    "    \"Puck\",         # 5\n",
    "    \"Referee\",      # 6\n",
    "]  # @param\n",
    "\n",
    "# === Class Filtering ===\n",
    "# Which classes to track (by class ID). Set to None to track all classes.\n",
    "TRACK_CLASSES = [3, 4, 5, 6]  # @param - Goaltender, Player, Puck, Referee\n",
    "\n",
    "# Special classes: keep only max-confidence detection per frame\n",
    "# Useful for small objects like puck where multiple false positives are common\n",
    "SPECIAL_CLASSES = [5]  # @param - Puck only\n",
    "\n",
    "# Set to True to disable class filtering and track all detected classes\n",
    "NO_CLASS_FILTER = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# === Tracker Selection ===\n",
    "# Options: \"mcbyte\", \"bytetrack\", \"sort\", \"deepsort\", \"botsort\", \"ocsort\"\n",
    "TRACKER_TYPE = \"mcbyte\"  # @param [\"mcbyte\", \"bytetrack\", \"sort\", \"deepsort\", \"botsort\", \"ocsort\"]\n",
    "\n",
    "# === Tracking Parameters ===\n",
    "TRACK_THRESH = 0.6  # @param {type:\"slider\", min:0.1, max:0.9, step:0.05}\n",
    "TRACK_BUFFER = 30  # @param {type:\"slider\", min:10, max:100, step:5}\n",
    "\n",
    "# === SAM Configuration ===\n",
    "# Uses values from previous cell\n",
    "SAM_CHECKPOINT = sam_path\n",
    "SAM_TYPE = sam_type\n",
    "\n",
    "# === Cutie Configuration ===\n",
    "CUTIE_WEIGHTS = cutie_path\n",
    "\n",
    "# === Other Options ===\n",
    "ENABLE_MASKS = True  # @param {type:\"boolean\"}\n",
    "VIS_TYPE = \"basic\"  # @param [\"basic\", \"no_vis\"]\n",
    "CONF_THRESH = 0.01  # @param {type:\"number\"}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  YOLOv8 weights: {YOLOV8_WEIGHTS}\")\n",
    "print(f\"  Class names: {CLASS_NAMES}\")\n",
    "print(f\"  Track classes: {TRACK_CLASSES if not NO_CLASS_FILTER else 'ALL'}\")\n",
    "print(f\"  Special classes (max-conf): {SPECIAL_CLASSES if not NO_CLASS_FILTER else 'NONE'}\")\n",
    "print(f\"  Tracker: {TRACKER_TYPE}\")\n",
    "print(f\"  Track threshold: {TRACK_THRESH}\")\n",
    "print(f\"  Track buffer: {TRACK_BUFFER}\")\n",
    "print(f\"  SAM type: {SAM_TYPE}\")\n",
    "print(f\"  Masks enabled: {ENABLE_MASKS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation Checks\n",
    "\n",
    "Verify that all components are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport cv2\nimport numpy as np\nimport sys\nimport os\n\ndef validate_setup():\n    \"\"\"Validate all components are working.\"\"\"\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"[1/4] Device: {device} ({'GPU: ' + torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'})\")\n\n    # === YOLOv8 Check ===\n    print(\"[2/4] Checking YOLOv8...\")\n    try:\n        from ultralytics import YOLO\n        model = YOLO(YOLOV8_WEIGHTS)\n        test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n        results = model(test_img, verbose=False)\n        print(f\"  [OK] YOLOv8 loaded: {len(model.names)} classes\")\n        print(f\"  [OK] Custom classes: {CLASS_NAMES}\")\n        del model\n    except Exception as e:\n        print(f\"  [FAIL] YOLOv8: {e}\")\n        return False\n\n    # === SAM Check ===\n    print(\"[3/4] Checking SAM...\")\n    try:\n        if SAM_TYPE == \"sam2\":\n            # SAM2 requires config file + checkpoint\n            from sam2.build_sam import build_sam2\n            from sam2.sam2_image_predictor import SAM2ImagePredictor\n\n            # SAM2 config mapping\n            sam2_configs = {\n                \"sam2_hiera_large.pt\": \"configs/sam2.1/sam2.1_hiera_l.yaml\",\n                \"sam2_hiera_base_plus.pt\": \"configs/sam2.1/sam2.1_hiera_b+.yaml\",\n                \"sam2_hiera_small.pt\": \"configs/sam2.1/sam2.1_hiera_s.yaml\",\n                \"sam2_hiera_tiny.pt\": \"configs/sam2.1/sam2.1_hiera_t.yaml\",\n            }\n\n            # Get config for checkpoint\n            ckpt_name = os.path.basename(SAM_CHECKPOINT)\n            config_file = sam2_configs.get(ckpt_name, \"configs/sam2.1/sam2.1_hiera_l.yaml\")\n\n            sam = build_sam2(config_file, ckpt_path=SAM_CHECKPOINT, device=device)\n            predictor = SAM2ImagePredictor(sam)\n        else:\n            from segment_anything import sam_model_registry, SamPredictor\n            sam = sam_model_registry[SAM_TYPE](checkpoint=SAM_CHECKPOINT)\n            sam.to(device)\n            predictor = SamPredictor(sam)\n\n        test_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n        predictor.set_image(test_img)\n        masks, scores, _ = predictor.predict(\n            box=np.array([100, 100, 300, 300]),\n            multimask_output=False\n        )\n        print(f\"  [OK] SAM working: mask shape {masks.shape}, score {scores[0]:.3f}\")\n        del sam, predictor\n    except Exception as e:\n        print(f\"  [FAIL] SAM: {e}\")\n        return False\n\n    # === Cutie Check ===\n    print(\"[4/4] Checking Cutie...\")\n    try:\n        # Get absolute path to Cutie config directory\n        cutie_base = os.path.abspath(\"mask_propagation/Cutie\")\n        cutie_config_dir = os.path.join(cutie_base, \"cutie\", \"config\")\n\n        # Check config directory exists\n        if not os.path.isdir(cutie_config_dir):\n            raise FileNotFoundError(\n                f\"Cutie config directory not found at: {cutie_config_dir}\\n\"\n                \"Make sure you're in the McByte directory and Cutie is properly cloned.\"\n            )\n\n        sys.path.insert(0, cutie_base)\n        from cutie.model.cutie import CUTIE\n        from hydra import initialize_config_dir, compose\n        from hydra.core.global_hydra import GlobalHydra\n        from omegaconf import open_dict\n        from cutie.inference.utils.args_utils import get_dataset_cfg\n\n        GlobalHydra.instance().clear()\n        # Use initialize_config_dir with absolute path instead of initialize with relative path\n        initialize_config_dir(version_base='1.3.2', config_dir=cutie_config_dir)\n        cfg = compose(config_name=\"eval_config\")\n\n        with open_dict(cfg):\n            cfg['weights'] = CUTIE_WEIGHTS\n\n        _ = get_dataset_cfg(cfg)\n\n        cutie = CUTIE(cfg).to(device).eval()\n        weights = torch.load(CUTIE_WEIGHTS, map_location=device)\n        cutie.load_weights(weights)\n        print(\"  [OK] Cutie loaded successfully\")\n        del cutie\n    except Exception as e:\n        print(f\"  [FAIL] Cutie: {e}\")\n        return False\n\n    # Cleanup\n    torch.cuda.empty_cache()\n\n    print(\"\\n\" + \"=\"*50)\n    print(\"[OK] All validation checks passed!\")\n    print(\"=\"*50)\n    return True\n\n# Run validation\nvalidation_passed = validate_setup()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Inference\n",
    "\n",
    "Upload your video and run tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from tools.colab_inference import run_inference\n",
    "\n",
    "# Upload video\n",
    "print(\"Please upload your video file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    video_path = list(uploaded.keys())[0]\n",
    "    print(f\"\\nUploaded: {video_path}\")\n",
    "else:\n",
    "    raise ValueError(\"No video uploaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tracking with masks\n",
    "print(\"Starting inference...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "output_path = run_inference(\n",
    "    video_path=video_path,\n",
    "    yolov8_weights=YOLOV8_WEIGHTS,\n",
    "    tracker_type=TRACKER_TYPE,\n",
    "    track_thresh=TRACK_THRESH,\n",
    "    track_buffer=TRACK_BUFFER,\n",
    "    sam_checkpoint=SAM_CHECKPOINT,\n",
    "    sam_type=SAM_TYPE,\n",
    "    cutie_weights=CUTIE_WEIGHTS,\n",
    "    enable_masks=ENABLE_MASKS,\n",
    "    # Class filtering options\n",
    "    track_classes=TRACK_CLASSES if not NO_CLASS_FILTER else None,\n",
    "    special_classes=SPECIAL_CLASSES if not NO_CLASS_FILTER else None,\n",
    "    no_class_filter=NO_CLASS_FILTER,\n",
    "    # Other options\n",
    "    class_names=CLASS_NAMES,\n",
    "    vis_type=VIS_TYPE,\n",
    "    conf_thresh=CONF_THRESH,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nOutput saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display and Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "from base64 import b64encode\n",
    "import os\n",
    "\n",
    "# Display video in notebook\n",
    "def show_video(video_path, width=800):\n",
    "    \"\"\"Display video in notebook.\"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video not found: {video_path}\")\n",
    "        return\n",
    "\n",
    "    # Read video file\n",
    "    with open(video_path, 'rb') as f:\n",
    "        mp4 = f.read()\n",
    "\n",
    "    # Encode to base64\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "\n",
    "    # Display\n",
    "    display(HTML(f'''\n",
    "        <video width={width} controls>\n",
    "            <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "            Your browser does not support the video tag.\n",
    "        </video>\n",
    "    '''))\n",
    "\n",
    "print(\"Displaying output video...\")\n",
    "show_video(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download output video\n",
    "from google.colab import files\n",
    "\n",
    "print(f\"Downloading: {output_path}\")\n",
    "files.download(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (Optional) Process Multiple Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing example\n",
    "import os\n",
    "from tools.colab_inference import run_inference\n",
    "\n",
    "def process_videos_batch(video_dir, output_dir=\"outputs\"):\n",
    "    \"\"\"\n",
    "    Process all videos in a directory.\n",
    "\n",
    "    Args:\n",
    "        video_dir: Directory containing input videos\n",
    "        output_dir: Directory for output videos\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
    "    videos = [\n",
    "        f for f in os.listdir(video_dir)\n",
    "        if any(f.lower().endswith(ext) for ext in video_extensions)\n",
    "    ]\n",
    "\n",
    "    print(f\"Found {len(videos)} videos to process\")\n",
    "\n",
    "    results = []\n",
    "    for i, video_name in enumerate(videos, 1):\n",
    "        print(f\"\\n[{i}/{len(videos)}] Processing: {video_name}\")\n",
    "\n",
    "        input_path = os.path.join(video_dir, video_name)\n",
    "        output_name = f\"tracked_{video_name}\"\n",
    "        output_path = os.path.join(output_dir, output_name)\n",
    "\n",
    "        try:\n",
    "            result = run_inference(\n",
    "                video_path=input_path,\n",
    "                yolov8_weights=YOLOV8_WEIGHTS,\n",
    "                output_path=output_path,\n",
    "                tracker_type=TRACKER_TYPE,\n",
    "                track_thresh=TRACK_THRESH,\n",
    "                track_buffer=TRACK_BUFFER,\n",
    "                sam_checkpoint=SAM_CHECKPOINT,\n",
    "                sam_type=SAM_TYPE,\n",
    "                cutie_weights=CUTIE_WEIGHTS,\n",
    "                enable_masks=ENABLE_MASKS,\n",
    "                # Class filtering options\n",
    "                track_classes=TRACK_CLASSES if not NO_CLASS_FILTER else None,\n",
    "                special_classes=SPECIAL_CLASSES if not NO_CLASS_FILTER else None,\n",
    "                no_class_filter=NO_CLASS_FILTER,\n",
    "                # Other options\n",
    "                class_names=CLASS_NAMES,\n",
    "                verbose=False,\n",
    "            )\n",
    "            results.append((video_name, result, \"success\"))\n",
    "            print(f\"  [OK] Output: {result}\")\n",
    "        except Exception as e:\n",
    "            results.append((video_name, None, str(e)))\n",
    "            print(f\"  [FAIL] {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Batch processing complete!\")\n",
    "    print(f\"Success: {sum(1 for r in results if r[2] == 'success')}/{len(results)}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "# results = process_videos_batch(\"/content/videos\", \"/content/outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. (Optional) Custom Tracker Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using different trackers with custom parameters\n",
    "from tools.tracker_interface import create_tracker, list_available_trackers\n",
    "\n",
    "# List available trackers\n",
    "print(\"Available trackers:\")\n",
    "for tracker_name in list_available_trackers():\n",
    "    print(f\"  - {tracker_name}\")\n",
    "\n",
    "# Example configurations for different trackers:\n",
    "\n",
    "# McByte (default - with mask-enhanced matching)\n",
    "mcbyte_tracker = create_tracker(\n",
    "    tracker_type=\"mcbyte\",\n",
    "    track_thresh=0.6,\n",
    "    track_buffer=30,\n",
    "    cmc_method=\"orb\",  # Camera motion compensation\n",
    ")\n",
    "\n",
    "# ByteTrack (standard, without mask enhancement)\n",
    "bytetrack_tracker = create_tracker(\n",
    "    tracker_type=\"bytetrack\",\n",
    "    track_thresh=0.5,\n",
    "    track_buffer=30,\n",
    ")\n",
    "\n",
    "# SORT (simple Kalman + Hungarian)\n",
    "sort_tracker = create_tracker(\n",
    "    tracker_type=\"sort\",\n",
    "    track_buffer=30,\n",
    "    min_hits=3,\n",
    "    iou_threshold=0.3,\n",
    ")\n",
    "\n",
    "# DeepSORT (with ReID features)\n",
    "# Note: Requires pip install deep-sort-realtime\n",
    "# deepsort_tracker = create_tracker(\n",
    "#     tracker_type=\"deepsort\",\n",
    "#     track_buffer=30,\n",
    "#     n_init=3,\n",
    "#     embedder=\"mobilenet\",\n",
    "# )\n",
    "\n",
    "print(\"\\nTrackers configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **CUDA out of memory**: Reduce `max_internal_size` in Cutie config or use a smaller SAM model (vit_b)\n",
    "\n",
    "2. **YOLOv8 model not found**: Make sure you've uploaded your .pt file and set the correct path\n",
    "\n",
    "3. **SAM download failed**: Manually download from the URLs and upload to Colab\n",
    "\n",
    "4. **Tracker package not found**: Install the required package:\n",
    "   - SORT: `pip install sort-tracker`\n",
    "   - DeepSORT: `pip install deep-sort-realtime`\n",
    "   - OC-SORT: `pip install ocsort`\n",
    "\n",
    "### Memory Optimization:\n",
    "\n",
    "Edit `mask_propagation/Cutie/cutie/config/eval_config.yaml`:\n",
    "```yaml\n",
    "max_internal_size: 540  # Reduce from -1 (original resolution)\n",
    "```\n",
    "\n",
    "### Class Filtering Options:\n",
    "\n",
    "The notebook supports filtering which classes to track:\n",
    "\n",
    "```python\n",
    "# Track only specific classes (by class ID)\n",
    "TRACK_CLASSES = [3, 4, 5, 6]  # Goaltender, Player, Puck, Referee\n",
    "\n",
    "# Keep only max-confidence detection for small objects\n",
    "SPECIAL_CLASSES = [5]  # Puck - avoids multiple false positives\n",
    "\n",
    "# Disable filtering to track all detected classes\n",
    "NO_CLASS_FILTER = True\n",
    "```\n",
    "\n",
    "**Default Hockey Classes:**\n",
    "| ID | Class Name |\n",
    "|----|------------|\n",
    "| 0  | Center Ice |\n",
    "| 1  | Faceoff |\n",
    "| 2  | Goalpost |\n",
    "| 3  | Goaltender |\n",
    "| 4  | Player |\n",
    "| 5  | Puck |\n",
    "| 6  | Referee |\n",
    "\n",
    "---\n",
    "\n",
    "**McByte** - CVPRW 2025 | [GitHub](https://github.com/HiteshG/McByte)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}